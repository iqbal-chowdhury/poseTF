{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Mayank Oct 10 2016\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import os,sys,shutil\n",
    "import tempfile,copy,re\n",
    "from enum import Enum\n",
    "import localSetup\n",
    "\n",
    "import caffe,lmdb\n",
    "import caffe.proto.caffe_pb2\n",
    "from caffe.io import datum_to_array\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as manimation\n",
    "import math,cv2,scipy,time,pickle\n",
    "import numpy as np\n",
    "\n",
    "import PoseTools,myutils,multiResData\n",
    "\n",
    "import convNetBase as CNB\n",
    "from batch_norm import batch_norm\n",
    "import PoseTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoseRegression(PoseTrain.PoseTrain):\n",
    "    \n",
    "    def createPH(self):\n",
    "        super(PoseRegression,self).createPH()\n",
    "        scale = self.conf.rescale*self.conf.pool_scale\n",
    "        lsz0 = self.conf.imsz[0]/scale\n",
    "        lsz1 = self.conf.imsz[1]/scale\n",
    "        n_classes = self.conf.n_classes\n",
    "        regx_ph = tf.placeholder(tf.float32, [None, lsz0,lsz1,n_classes],'regx')\n",
    "        self.ph['regx'] = regx_ph\n",
    "        regy_ph = tf.placeholder(tf.float32, [None, lsz0,lsz1,n_classes],'regy')\n",
    "        self.ph['regy'] = regy_ph\n",
    "\n",
    "    \n",
    "    def updateFeedDict(self,dbtype,distort):\n",
    "        super(PoseRegression,self).updateFeedDict(dbtype,distort)\n",
    "        \n",
    "        labelims,regimsx,regimsy = PoseTools.createRegLabelImages(self.locs,\n",
    "                                   self.conf.imsz,\n",
    "                                   self.conf.pool_scale*self.conf.rescale,\n",
    "                                   self.conf.label_blur_rad)\n",
    "        self.feed_dict[self.ph['y']] = labelims\n",
    "        self.feed_dict[self.ph['regx']] = regimsx\n",
    "        self.feed_dict[self.ph['regy']] = regimsy\n",
    "        \n",
    "    def createLoss(self):\n",
    "        label_cost = tf.nn.l2_loss(self.baseregPred-self.ph['y']) \n",
    "        norm_label = tf.sqrt(tf.maximum((self.ph['y']/2)+0.5,0))\n",
    "        # sqrt so that in l2_loss it becomes what we want\n",
    "        xcost = tf.mul(self.regpredx-self.ph['regx'],norm_label)\n",
    "        ycost = tf.mul(self.regpredy-self.ph['regy'],norm_label)\n",
    "\n",
    "        rad = self.conf.label_blur_rad*2*self.conf.pool_scale\n",
    "        # dividing xcost and ycost by rad so that if we are off by rad in regression\n",
    "        # it is equivalent to complete misprediction on labels\n",
    "        reg_cost = tf.nn.l2_loss(xcost/rad) + tf.nn.l2_loss(ycost/rad)\n",
    "        \n",
    "        reg_lambda = self.conf.reg_lambda\n",
    "        self.cost = label_cost + reg_lambda*(reg_cost)\n",
    "\n",
    "    def createBaseReg(self,doBatchNorm):\n",
    "        pred,predx,predy,layers = CNB.net_multi_conv_reg(self.ph['x0'],self.ph['x1'],\n",
    "                                         self.ph['x2'],self.ph['keep_prob'],\n",
    "                                         self.conf,doBatchNorm,\n",
    "                                         self.ph['phase_train_base']\n",
    "                                        )\n",
    "        self.baseregPred = pred\n",
    "        self.regpredx = predx\n",
    "        self.regpredy = predy\n",
    "        self.baseLayers = layers\n",
    "        \n",
    "    def createBaseRegSaver(self):\n",
    "        self.baseregsaver = tf.train.Saver(var_list = PoseTools.getvars('regbase'),\n",
    "                                        max_to_keep=self.conf.maxckpt)\n",
    "        \n",
    "    def restoreBaseReg(self,sess,restore):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.baseregoutname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.baseregdataname)\n",
    "        latest_ckpt = tf.train.get_checkpoint_state(self.conf.cachedir,\n",
    "                                            latest_filename = self.conf.baseregckptname)\n",
    "        if not latest_ckpt or not restore:\n",
    "            self.baseregstartat = 0\n",
    "            self.baseregtrainData = {'train_err':[], 'val_err':[], 'step_no':[],\n",
    "                                  'train_dist':[], 'val_dist':[] }\n",
    "            sess.run(tf.initialize_variables(PoseTools.getvars('base')))\n",
    "            print(\"Not loading base variables. Initializing them\")\n",
    "            return False\n",
    "        else:\n",
    "            self.baseregsaver.restore(sess,latest_ckpt.model_checkpoint_path)\n",
    "            matchObj = re.match(outfilename + '-(\\d*)',latest_ckpt.model_checkpoint_path)\n",
    "            self.baseregstartat = int(matchObj.group(1))+1\n",
    "            with open(traindatafilename,'rb') as tdfile:\n",
    "                inData = pickle.load(tdfile)\n",
    "                if not isinstance(inData,dict):\n",
    "                    self.baseregtrainData, loadconf = inData\n",
    "                    print('Parameters that dont match for base:')\n",
    "                    PoseTools.compareConf(self.conf, loadconf)\n",
    "                else:\n",
    "                    print(\"No config was stored for base. Not comparing conf\")\n",
    "                    self.baseregtrainData = inData\n",
    "            print(\"Loading base variables from %s\"%latest_ckpt.model_checkpoint_path)\n",
    "            return True\n",
    "            \n",
    "    def saveBaseReg(self,sess,step):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.baseregoutname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.baseregdataname)\n",
    "        self.baseregsaver.save(sess,outfilename,global_step=step,\n",
    "                   latest_filename = self.conf.baseregckptname)\n",
    "        print('Saved state to %s-%d' %(outfilename,step))\n",
    "        with open(traindatafilename,'wb') as tdfile:\n",
    "            pickle.dump([self.baseregtrainData,self.conf],tdfile)\n",
    "            \n",
    "    def updateBaseRegLoss(self,step,train_loss,val_loss,trainDist,valDist):\n",
    "        print \"Iter \" + str(step) + \\\n",
    "             \", Train = \" + \"{:.3f},{:.1f}\".format(train_loss[0],trainDist[0]) + \\\n",
    "             \", Val = \" + \"{:.3f},{:.1f}\".format(val_loss[0],valDist[0])\n",
    "#         nstep = step-self.basestartat\n",
    "#         print \"  Read Time:\" + \"{:.2f}, \".format(self.read_time/(nstep+1)) + \\\n",
    "#               \"Opt Time:\" + \"{:.2f}\".format(self.opt_time/(nstep+1)) \n",
    "        self.baseregtrainData['train_err'].append(train_loss[0])      \n",
    "        self.baseregtrainData['val_err'].append(val_loss[0])        \n",
    "        self.baseregtrainData['step_no'].append(step)        \n",
    "        self.baseregtrainData['train_dist'].append(trainDist[0])        \n",
    "        self.baseregtrainData['val_dist'].append(valDist[0])        \n",
    "\n",
    "        \n",
    "    def baseRegress(self, restore=True, trainPhase=True):\n",
    "        self.createPH()\n",
    "        self.createFeedDict()\n",
    "        self.feed_dict[self.ph['phase_train_base']] = trainPhase\n",
    "        self.feed_dict[self.ph['keep_prob']] = 0.5\n",
    "        doBatchNorm = self.conf.doBatchNorm\n",
    "        \n",
    "        with tf.variable_scope('regbase'):\n",
    "            self.createBaseReg(doBatchNorm)\n",
    "        \n",
    "        self.createLoss()\n",
    "        self.openDBs()\n",
    "        self.createOptimizer()\n",
    "        self.createBaseRegSaver()\n",
    "\n",
    "        with self.env.begin() as txn,\\\n",
    "                 self.valenv.begin() as valtxn,\\\n",
    "                 tf.Session() as sess:\n",
    "                    \n",
    "            self.createCursors(txn,valtxn)\n",
    "            self.restoreBaseReg(sess,restore)\n",
    "            self.initializeRemainingVars(sess)\n",
    "            \n",
    "            for step in range(self.baseregstartat,self.conf.basereg_training_iters+1):\n",
    "                self.feed_dict[self.ph['keep_prob']] = 0.5\n",
    "                self.doOpt(sess,step,self.conf.base_learning_rate)\n",
    "                if step % self.conf.display_step == 0:\n",
    "                    self.updateFeedDict(self.DBType.Train,distort=True)\n",
    "                    self.feed_dict[self.ph['keep_prob']] = 1.\n",
    "                    train_loss = self.computeLoss(sess,[self.cost])\n",
    "                    tt1 = self.computePredDist(sess,self.baseregPred)\n",
    "                    trainDist = [tt1.mean()]\n",
    "                    numrep = int(self.conf.numTest/self.conf.batch_size)+1\n",
    "                    val_loss = np.zeros([2,])\n",
    "                    valDist = [0.]\n",
    "                    for rep in range(numrep):\n",
    "                        self.updateFeedDict(self.DBType.Val,distort=False)\n",
    "                        val_loss += np.array(self.computeLoss(sess,[self.cost]))\n",
    "                        tt1 = self.computePredDist(sess,self.baseregPred)\n",
    "                        valDist = [valDist[0]+tt1.mean()]\n",
    "                    val_loss = val_loss/numrep\n",
    "                    valDist = [valDist[0]/numrep]\n",
    "                    self.updateBaseRegLoss(step,train_loss,val_loss,trainDist,valDist)\n",
    "                if step % self.conf.save_step == 0:\n",
    "                    self.saveBaseReg(sess,step)\n",
    "            print(\"Optimization Finished!\")\n",
    "            self.saveBaseReg(sess,step)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
