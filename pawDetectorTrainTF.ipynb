{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Mayank Jan 12 2016\n",
    "Paw detector modified from:\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os,sys\n",
    "sys.path.append('/home/mayank/work/caffe/python')\n",
    "\n",
    "import caffe\n",
    "import lmdb\n",
    "import caffe.proto.caffe_pb2\n",
    "\n",
    "from caffe.io import datum_to_array\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.0005\n",
    "training_iters = 20000\n",
    "batch_size = 128\n",
    "display_step = 30\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 128 # patch size\n",
    "n_classes = 2 # \n",
    "dropout = 0.5 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout(keep probability)\n",
    "x = tf.placeholder(tf.float32, [None, n_input,n_input,3])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "x_conv = tf.placeholder(tf.float32, [1, None,None,3])\n",
    "\n",
    "\n",
    "val_env = lmdb.open('/home/mayank/work/ChenCode/cache/paw/LMDB_val/',readonly=True)\n",
    "val_txn = val_env.begin()\n",
    "val_cursor = val_txn.cursor()\n",
    "lmdb_env = lmdb.open('/home/mayank/work/ChenCode/cache/paw/LMDB_train/',readonly=True)\n",
    "lmdb_txn = lmdb_env.begin()\n",
    "lmdb_cursor = lmdb_txn.cursor()\n",
    "datum = caffe.proto.caffe_pb2.Datum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readLMDB(cursor,num,n_input,n_classes):\n",
    "    images = np.zeros((num,n_input,n_input,3))\n",
    "    labels = np.zeros((num,n_classes))\n",
    "    datum = caffe.proto.caffe_pb2.Datum()\n",
    "\n",
    "#     print(images.shape)\n",
    "    for ndx in range(num):\n",
    "        if not cursor.next():\n",
    "            cursor.first()\n",
    "#             print('restarting at %d' % ndx)\n",
    "            \n",
    "        value = cursor.value()\n",
    "        datum.ParseFromString(value)\n",
    "        curlabel = datum.label\n",
    "        data = caffe.io.datum_to_array(datum)\n",
    "        data = np.transpose(data,(1,2,0))\n",
    "        images[ndx,:,:,:] = data\n",
    "        labels[ndx,curlabel] = 1\n",
    "    return images,labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create AlexNet model\n",
    "def conv2d(name, l_input, w, b):\n",
    "    return tf.nn.relu(\n",
    "        tf.nn.bias_add(\n",
    "            tf.nn.conv2d(\n",
    "                l_input, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            ,b), \n",
    "        name=name)\n",
    "\n",
    "def max_pool(name, l_input, k,s):\n",
    "    return tf.nn.max_pool(\n",
    "        l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], \n",
    "        padding='SAME', name=name)\n",
    "\n",
    "def norm(name, l_input, lsize=4):\n",
    "    return tf.nn.lrn(\n",
    "        l_input, lsize, bias=1.0, alpha=0.0001 , beta=0.75, \n",
    "        name=name)\n",
    "\n",
    "def paw_net(_X, _weights, _biases, _dropout):\n",
    "    \n",
    "    # L1\n",
    "    conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'])\n",
    "    pool1 = max_pool('pool1', conv1, k=3,s=2)\n",
    "    norm1 = norm('norm1', pool1, lsize=2)\n",
    "\n",
    "    #L2\n",
    "    conv2 = conv2d('conv2', norm1, _weights['wc2'], _biases['bc2'])\n",
    "    pool2 = max_pool('pool2', conv2, k=3,s=2)\n",
    "    norm2 = norm('norm2', pool2, lsize=4)\n",
    "\n",
    "    # L3,L4,L5\n",
    "    conv3 = conv2d('conv3', norm2, _weights['wc3'], _biases['bc3'])\n",
    "    conv4 = conv2d('conv4', conv3, _weights['wc4'], _biases['bc4'])\n",
    "    conv5 = conv2d('conv5', conv4, _weights['wc5'], _biases['bc5'])\n",
    "  \n",
    "    # Reshape conv5 output to fit dense layer input\n",
    "    fc6 = tf.reshape(conv5, [-1, _weights['wd1'].get_shape().as_list()[0]]) \n",
    "    fc6 = tf.nn.relu(tf.matmul(fc6, _weights['wd1']) + _biases['bd1'], name='fc6') \n",
    "    fc6 = tf.nn.dropout(fc6, _dropout)\n",
    "\n",
    "    \n",
    "    fc7 = tf.nn.relu(tf.matmul(fc6, _weights['wd2']) + _biases['bd2'], name='fc6') \n",
    "    fc7 = tf.nn.dropout(fc7, _dropout)\n",
    "    \n",
    "    # Output, class prediction\n",
    "    out = tf.matmul(fc7, _weights['out']) + _biases['out']\n",
    "    \n",
    "    layers = {'conv1': conv1,'pool1':pool1,'norm1':norm1,\n",
    "              'conv2': conv2,'pool2':pool2,'norm2':norm2,\n",
    "              'conv3':conv3, 'conv4':conv4,'conv5':conv5,\n",
    "              'fc6':fc6,'fc7':fc7,'fc8':out\n",
    "             }\n",
    "\n",
    "    return out,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paw_net_conv(_X, _weights, _biases,):\n",
    "    \n",
    "    # L1\n",
    "    conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'])\n",
    "    pool1 = max_pool('pool1', conv1, k=3,s=2)\n",
    "    norm1 = norm('norm1', pool1, lsize=2)\n",
    "\n",
    "    #L2\n",
    "    conv2 = conv2d('conv2', norm1, _weights['wc2'], _biases['bc2'])\n",
    "    pool2 = max_pool('pool2', conv2, k=3,s=2)\n",
    "    norm2 = norm('norm2', pool2, lsize=4)\n",
    "\n",
    "    # L3,L4,L5\n",
    "    conv3 = conv2d('conv3', norm2, _weights['wc3'], _biases['bc3'])\n",
    "    conv4 = conv2d('conv4', conv3, _weights['wc4'], _biases['bc4'])\n",
    "    conv5 = conv2d('conv5', conv4, _weights['wc5'], _biases['bc5'])\n",
    "  \n",
    "    # Reshape conv5 output to fit dense layer input\n",
    "#     fc6 = tf.reshape(conv5, [-1, _weights['wd1'].get_shape().as_list()[0]]) \n",
    "#     fc6 = tf.nn.relu(tf.matmul(fc6, _weights['wd1']) + _biases['bd1'], name='fc6') \n",
    "#     fc6 = tf.nn.dropout(fc6, _dropout)\n",
    "\n",
    "    \n",
    "#     fc7 = tf.nn.relu(tf.matmul(fc6, _weights['wd2']) + _biases['bd2'], name='fc6') \n",
    "#     fc7 = tf.nn.dropout(fc7, _dropout)\n",
    "    \n",
    "#     # Output, class prediction\n",
    "#     out = tf.matmul(fc7, _weights['out']) + _biases['out']\n",
    "  \n",
    "    conv6 = conv2d('conv6',conv5,_weights['wd_mod1'],_biases['bd1'])\n",
    "    conv7 = conv2d('conv7',conv6,_weights['wd_mod2'],_biases['bd2'])\n",
    "    out = tf.nn.bias_add(tf.nn.conv2d(\n",
    "                conv7, _weights['wd_mod3'], \n",
    "                strides=[1, 1, 1, 1], padding='SAME'),_biases['out'])\n",
    "\n",
    "    \n",
    "    conv2d('conv8',conv7,_weights['wd_mod3'],_biases['out'])\n",
    "    \n",
    "    layers = {'conv1': conv1,'pool1':pool1,'norm1':norm1,\n",
    "              'conv2': conv2,'pool2':pool2,'norm2':norm2,\n",
    "              'conv3':conv3, 'conv4':conv4,'conv5':conv5,\n",
    "              'conv6':conv6, 'conv7':conv7,'conv8':out,\n",
    "             }\n",
    "\n",
    "    return out,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 3, 48],stddev=0.01)),\n",
    "    'wc2': tf.Variable(tf.random_normal([3, 3, 48, 128],stddev=0.01)),\n",
    "    'wc3': tf.Variable(tf.random_normal([3, 3, 128, 128],stddev=0.01)),\n",
    "    'wc4': tf.Variable(tf.random_normal([3, 3, 128, 128],stddev=0.01)),\n",
    "    'wc5': tf.Variable(tf.random_normal([3, 3, 128, 128],stddev=0.01)),\n",
    "    'wd1': tf.Variable(tf.random_normal([32*32*128, 1024],stddev=0.005)),\n",
    "    'wd2': tf.Variable(tf.random_normal([1024, 1024],stddev=0.005)),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes],stddev=0.01))\n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.zeros([48])),\n",
    "    'bc2': tf.Variable(tf.ones([128])),\n",
    "    'bc3': tf.Variable(tf.ones([128])),\n",
    "    'bc4': tf.Variable(tf.ones([128])),\n",
    "    'bc5': tf.Variable(tf.ones([128])),\n",
    "    'bd1': tf.Variable(tf.ones([1024])),\n",
    "    'bd2': tf.Variable(tf.ones([1024])),\n",
    "    'out': tf.Variable(tf.zeros([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights_conv = {\n",
    "    'wc1': weights['wc1'],\n",
    "    'wc2': weights['wc2'],\n",
    "    'wc3': weights['wc3'],\n",
    "    'wc4': weights['wc4'],\n",
    "    'wc5': weights['wc5'],\n",
    "    'wd_mod1': tf.reshape(weights['wd1'],[32,32,128,1024]),\n",
    "    'wd_mod2': tf.reshape(weights['wd2'],[1,1,1024,1024]),\n",
    "    'wd_mod3': tf.reshape(weights['out'],[1,1,1024,2])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "[pred,layers] = paw_net(x, weights, biases, keep_prob)\n",
    "\n",
    "[pred_conv,layers_conv] = paw_net_conv(x_conv, weights_conv, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ***** train a detector *****\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step < training_iters:\n",
    "        batch_xs, batch_ys = readLMDB(lmdb_cursor,batch_size,n_input,n_classes)\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})\n",
    "#         acc = sess.run(accuracy, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "#         loss = sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})\n",
    "#         print \"Iter \" + str(step) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc)\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            val_xs, val_ys = readLMDB(val_cursor,batch_size*4,n_input,n_classes)\n",
    "            acc = sess.run(accuracy, feed_dict={x: val_xs, y: val_ys, keep_prob: 1.})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: val_xs, y: val_ys, keep_prob: 1.})\n",
    "            print \"**** Iter \" + str(step) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Validation Accuracy= \" + \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **** Compare a plain detector to convolution one *****\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('/home/mayank/Dropbox/AdamVideos/3rd_T/20140501/M119_20140501_v006/movie_comb.avi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Capture frame-by-frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "frame = frame[:,0:352,:]\n",
    "print(frame.shape)\n",
    "# Display the resulting frame\n",
    "plt.imshow(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frame = frame.astype('float32')\n",
    "aa = 0\n",
    "bb = 55\n",
    "sta = aa*4+1\n",
    "stb = bb*4+1\n",
    "patch = frame[np.newaxis,sta:sta+128,stb:stb+128,:]\n",
    "plt.imshow(frame[sta:sta+128,stb:stb+128,:]/255)\n",
    "frame_feed = frame[np.newaxis,:]\n",
    "label = np.array([[0.,1.]]).astype('float32')\n",
    "\n",
    "\n",
    "out = sess.run([pred,pred_conv],feed_dict=\n",
    "               {x:patch-33,y:label,\n",
    "                x_conv:frame_feed-33,\n",
    "               keep_prob:1.})\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "print(out[0])\n",
    "jja = aa+15\n",
    "jjb = bb+15\n",
    "print([jja,jjb])\n",
    "print(out[1][:,jja,jjb,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
