{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Mayank Jan 12 2016\n",
    "Paw detector modified from:\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os,sys\n",
    "import setupLocal\n",
    "\n",
    "import caffe\n",
    "import lmdb\n",
    "import caffe.proto.caffe_pb2\n",
    "# import pawconfig as conf\n",
    "\n",
    "from caffe.io import datum_to_array\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import multiPawTools\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import matplotlib.animation as manimation\n",
    "sys.path.append('/home/mayank/work/pyutils')\n",
    "import myutils\n",
    "import tempfile\n",
    "import copy\n",
    "\n",
    "\n",
    "def conv2d(name, l_input, w, b):\n",
    "    return tf.nn.relu(\n",
    "        tf.nn.bias_add(\n",
    "            tf.nn.conv2d(\n",
    "                l_input, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            ,b), \n",
    "        name=name)\n",
    "\n",
    "def max_pool(name, l_input, k,s):\n",
    "    return tf.nn.max_pool(\n",
    "        l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], \n",
    "        padding='SAME', name=name)\n",
    "\n",
    "def norm(name, l_input, lsize=4):\n",
    "    return tf.nn.lrn(\n",
    "        l_input, lsize, bias=1.0, alpha=0.0001 , beta=0.75, \n",
    "        name=name)\n",
    "\n",
    "def upscale(name,l_input,sz):\n",
    "    l_out = tf.image.resize_nearest_neighbor(l_input,sz,name=name)\n",
    "    return l_out\n",
    "\n",
    "def initNetConvWeights(conf):\n",
    "    # Store layers weight & bias\n",
    "    nfilt = conf.nfilt\n",
    "    nfcfilt = conf.nfcfilt\n",
    "    n_classes = conf.n_classes\n",
    "    rescale = conf.rescale\n",
    "    pool_scale = conf.pool_scale\n",
    "    \n",
    "#     sz5 = int(math.ceil(conf.psz/rescale/pool_scale))\n",
    "    sz5 = conf.psz\n",
    "    weights = {\n",
    "        'base0': initBaseWeights(nfilt),\n",
    "        'base1': initBaseWeights(nfilt),\n",
    "        'base2': initBaseWeights(nfilt),       \n",
    "        'wd1': tf.Variable(tf.random_normal([sz5,sz5,conf.numscale*nfilt,nfcfilt],stddev=0.005)),\n",
    "        'wd2': tf.Variable(tf.random_normal([1,1,nfcfilt, nfcfilt],stddev=0.005)),\n",
    "        'wd3': tf.Variable(tf.random_normal([1,1,nfcfilt, n_classes],stddev=0.01)),\n",
    "        'bd1': tf.Variable(tf.ones([nfcfilt])),\n",
    "        'bd2': tf.Variable(tf.ones([nfcfilt])),\n",
    "        'bd3': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "    return weights\n",
    "\n",
    "def initBaseWeights(nfilt):\n",
    "    \n",
    "    weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 48],stddev=0.01)),\n",
    "    'wc2': tf.Variable(tf.random_normal([3, 3, 48, nfilt],stddev=0.01)),\n",
    "    'wc3': tf.Variable(tf.random_normal([3, 3, nfilt, nfilt],stddev=0.01)),\n",
    "    'wc4': tf.Variable(tf.random_normal([3, 3, nfilt, nfilt],stddev=0.01)),\n",
    "    'wc5': tf.Variable(tf.random_normal([3, 3, nfilt, nfilt],stddev=0.01)),\n",
    "    'bc1': tf.Variable(tf.zeros([48])),\n",
    "    'bc2': tf.Variable(tf.ones([nfilt])),\n",
    "    'bc3': tf.Variable(tf.ones([nfilt])),\n",
    "    'bc4': tf.Variable(tf.ones([nfilt])),\n",
    "    'bc5': tf.Variable(tf.ones([nfilt]))\n",
    "    }\n",
    "    return weights\n",
    "\n",
    "def net_multi_base(X,_weights):\n",
    "    \n",
    "    conv1 = conv2d('conv1', X, _weights['wc1'], _weights['bc1'])\n",
    "    pool1 = max_pool('pool1', conv1, k=3,s=2)\n",
    "    norm1 = norm('norm1', pool1, lsize=2)\n",
    "    conv2 = conv2d('conv2', norm1, _weights['wc2'], _weights['bc2'])\n",
    "    pool2 = max_pool('pool2', conv2, k=3,s=2)\n",
    "    norm2 = norm('norm2', pool2, lsize=4)\n",
    "    conv3 = conv2d('conv3', norm2, _weights['wc3'], _weights['bc3'])\n",
    "    conv4 = conv2d('conv4', conv3, _weights['wc4'], _weights['bc4'])\n",
    "    conv5 = conv2d('conv5', conv4, _weights['wc5'], _weights['bc5'])\n",
    "    out_dict = {'conv1':conv1,'conv2':conv2,'conv3':conv3,\n",
    "                'conv4':conv4,'conv5':conv5,'pool1':pool1,\n",
    "                'pool2':pool2,'norm1':norm1,'norm2':norm2,\n",
    "               }\n",
    "    return conv5, out_dict\n",
    "\n",
    "def net_multi_base_named(X,nfilt):\n",
    "    with tf.variable_scope('layer1'):\n",
    "        conv1 = conv_relu(X,[5, 5, 1, 48],0.01,0)\n",
    "        pool1 = max_pool('pool1', conv1, k=3,s=2)\n",
    "        norm1 = norm('norm1', pool1, lsize=2)\n",
    "    with tf.variable_scope('layer2'):\n",
    "        conv2 = conv_relu(norm1,[3,3,48,nfilt],0.01,1)\n",
    "        pool2 = max_pool('pool2', conv2, k=3,s=2)\n",
    "        norm2 = norm('norm2', pool2, lsize=4)\n",
    "    with tf.variable_scope('layer3'):\n",
    "        conv3 = conv_relu(norm2,[3,3,nfilt,nfilt],0.01,1)\n",
    "    with tf.variable_scope('layer4'):\n",
    "        conv4 = conv_relu(conv3,[3,3,nfilt,nfilt],0.01,1)\n",
    "    with tf.variable_scope('layer5'):\n",
    "        conv5 = conv_relu(conv4,[3,3,nfilt,nfilt],0.01,1)\n",
    "        \n",
    "    out_dict = {'conv1':conv1,'conv2':conv2,'conv3':conv3,\n",
    "                'conv4':conv4,'conv5':conv5,'pool1':pool1,\n",
    "                'pool2':pool2,'norm1':norm1,'norm2':norm2,\n",
    "               }\n",
    "    return conv5,out_dict\n",
    "        \n",
    "\n",
    "def net_multi_conv(X0,X1,X2,_dropout,conf):\n",
    "    imsz = conf.imsz; rescale = conf.rescale\n",
    "    pool_scale = conf.pool_scale\n",
    "    nfilt = conf.nfilt\n",
    "    \n",
    "#     conv5_0,base_dict_0 = net_multi_base(X0,_weights['base0'])\n",
    "#     conv5_1,base_dict_1 = net_multi_base(X1,_weights['base1'])\n",
    "#     conv5_2,base_dict_2 = net_multi_base(X2,_weights['base2'])\n",
    "    with tf.variable_scope('scale0'):\n",
    "        conv5_0,base_dict_0 = net_multi_base_named(X0,nfilt)\n",
    "    with tf.variable_scope('scale1'):\n",
    "        conv5_1,base_dict_1 = net_multi_base_named(X1,nfilt)\n",
    "    with tf.variable_scope('scale2'):\n",
    "        conv5_2,base_dict_2 = net_multi_base_named(X2,nfilt)\n",
    "\n",
    "    sz0 = int(math.ceil(float(imsz[0])/pool_scale/rescale))\n",
    "    sz1 = int(math.ceil(float(imsz[1])/pool_scale/rescale))\n",
    "    conv5_1_up = upscale('5_1',conv5_1,[sz0,sz1])\n",
    "    conv5_2_up = upscale('5_2',conv5_2,[sz0,sz1])\n",
    "    conv5_cat = tf.concat(3,[conv5_0,conv5_1_up,conv5_2_up])\n",
    "    \n",
    "    # Reshape conv5 output to fit dense layer input\n",
    "#     conv6 = conv2d('conv6',conv5_cat,_weights['wd1'],_weights['bd1']) \n",
    "#     conv6 = tf.nn.dropout(conv6,_dropout)\n",
    "#     conv7 = conv2d('conv7',conv6,_weights['wd2'],_weights['bd2']) \n",
    "#     conv7 = tf.nn.dropout(conv7,_dropout)\n",
    "    with tf.variable_scope('layer6'):\n",
    "        conv6 = conv_relu(conv5_cat,[conf.psz,conf.psz,conf.numscale*nfilt,conf.nfcfilt],0.005,1) \n",
    "        conv6_sh = conv6.get_shape()\n",
    "        conv6 = tf.nn.dropout(conv6,_dropout,[conf.batch_size,1,1,conf.nfcfilt])\n",
    "    with tf.variable_scope('layer7'):\n",
    "        conv7 = conv_relu(conv6,[1,1,conf.nfcfilt,conf.nfcfilt],0.005,1) \n",
    "        conv7_sh = conv7.get_shape()\n",
    "        conv7 = tf.nn.dropout(conv7,_dropout,[conf.batch_size,1,1,conf.nfcfilt])\n",
    "\n",
    "# Output, class prediction\n",
    "#     out = tf.nn.bias_add(tf.nn.conv2d(\n",
    "#             conv7, _weights['wd3'], \n",
    "#             strides=[1, 1, 1, 1], padding='SAME'),_weights['bd3'])\n",
    "\n",
    "    with tf.variable_scope('layer8'):\n",
    "        l8_weights = tf.get_variable(\"weights\", [1,1,conf.nfcfilt,conf.n_classes],\n",
    "            initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        l8_biases = tf.get_variable(\"biases\", conf.n_classes,\n",
    "            initializer=tf.constant_initializer(0))\n",
    "        \n",
    "    out = tf.nn.conv2d(conv7, l8_weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME') + l8_biases\n",
    "        \n",
    "    out_dict = {'base_dict_0':base_dict_0,\n",
    "                'base_dict_1':base_dict_1,\n",
    "                'base_dict_2':base_dict_2,\n",
    "                'conv6':conv6,\n",
    "                'conv7':conv7,\n",
    "               }\n",
    "    \n",
    "    return out,out_dict\n",
    "\n",
    "\n",
    "def createPlaceHolders(imsz,rescale,scale,pool_scale,n_classes):\n",
    "#     imsz = conf.imsz\n",
    "    # tf Graph input\n",
    "    keep_prob = tf.placeholder(tf.float32) # dropout(keep probability)\n",
    "    x0 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/rescale,\n",
    "                                     imsz[1]/rescale,1])\n",
    "    x1 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/scale/rescale,\n",
    "                                     imsz[1]/scale/rescale,1])\n",
    "    x2 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/scale/scale/rescale,\n",
    "                                     imsz[1]/scale/scale/rescale,1])\n",
    "\n",
    "    lsz0,lsz1 = findPredSize(imsz,rescale,pool_scale)\n",
    "    y = tf.placeholder(tf.float32, [None, lsz0,lsz1,n_classes])\n",
    "    return x0,x1,x2,y,keep_prob\n",
    "\n",
    "def findPredSize(imsz,rescale,pool_scale):\n",
    "    lsz0 = int(math.ceil(float(imsz[0])/pool_scale/rescale))\n",
    "    lsz1 = int(math.ceil(float(imsz[1])/pool_scale/rescale))\n",
    "    return lsz0, lsz1\n",
    "\n",
    "def conv_relu(X, kernel_shape, conv_std,bias_val):\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer(stddev=conv_std))\n",
    "    biases = tf.get_variable(\"biases\", kernel_shape[-1],\n",
    "        initializer=tf.constant_initializer(bias_val))\n",
    "    conv = tf.nn.conv2d(X, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "\n",
    "def fine_base(X,conf,insize):\n",
    "    fsz = conf.fine_flt_sz\n",
    "    fine_nfilt = conf.fine_nfilt\n",
    "    with tf.variable_scope(\"fine_1\"):\n",
    "        conv1 = conv_relu(X, [fsz, fsz, insize, fine_nfilt],0.05,1)\n",
    "    with tf.variable_scope(\"fine_2\"):\n",
    "        conv2 = conv_relu(conv1, [fsz, fsz, fine_nfilt, fine_nfilt],0.05,1)\n",
    "    with tf.variable_scope(\"fine_3\"):\n",
    "        conv3 = conv_relu(conv2, [fsz, fsz, fine_nfilt, fine_nfilt/2],0.05,1)\n",
    "    return conv3\n",
    "\n",
    "    \n",
    "\n",
    "def fineNetwork(fineIn1_1,fineIn1_2,fineIn2_1,fineIn2_2, conf):\n",
    "    with tf.variable_scope('1_1'):\n",
    "        fine1_1 = fine_base(fineIn1_1,conf,48)\n",
    "    with tf.variable_scope('1_2'):\n",
    "        fine1_2 = fine_base(fineIn1_2,conf,conf.nfilt)\n",
    "    with tf.variable_scope('2_1'):\n",
    "        fine2_1 = fine_base(fineIn2_1,conf,48)\n",
    "    with tf.variable_scope('2_2'):\n",
    "        fine2_2 = fine_base(fineIn2_2,conf,conf.nfilt)\n",
    "\n",
    "    fsz = conf.fine_sz\n",
    "    fine1_2_up = upscale('fine1_2',fine1_2,[fsz,fsz])\n",
    "    fine2_1_up = upscale('fine2_1',fine2_1,[fsz,fsz])\n",
    "    fine2_2_up = upscale('fine2_2',fine2_2,[fsz,fsz])\n",
    "    fineSum = tf.add_n([fine1_1,fine1_2_up,fine2_1_up,fine2_2_up])\n",
    "    # for fine apparently adding is better than concatenating!!\n",
    "#     conv5_cat = tf.concat(3,[fine1_1,fine1_2_up,fine2_1_up,fine2_2_up])\n",
    "    return fineSum\n",
    "\n",
    "def fineOut(fineIn1_1,fineIn1_2,fineIn2_1,fineIn2_2,conf):\n",
    "    inter = []\n",
    "    with tf.variable_scope('fine_siamese') as scope:\n",
    "        tvar = fineNetwork(fineIn1_1[0],fineIn1_2[0],\n",
    "                                 fineIn2_1[0],fineIn2_2[0],conf)\n",
    "        inter.append(tvar)\n",
    "        scope.reuse_variables()\n",
    "        for ndx in range(1,len(fineIn1_1)):\n",
    "            tvar = fineNetwork(fineIn1_1[ndx],fineIn1_2[ndx],\n",
    "                                     fineIn2_1[ndx],fineIn2_2[ndx],conf)\n",
    "            inter.append(tvar)\n",
    "\n",
    "    fineLast = []\n",
    "    for ndx in range(len(fineIn1_1)):\n",
    "        with tf.variable_scope('point_' + str(ndx)):\n",
    "            weights = tf.get_variable(\"weights\", [1,1,conf.fine_nfilt/2,1],\n",
    "                initializer=tf.random_normal_initializer(stddev=0.05))\n",
    "            biases = tf.get_variable(\"biases\", 1,\n",
    "                initializer=tf.constant_initializer(0))\n",
    "            conv = tf.nn.conv2d(inter[ndx], weights,\n",
    "                strides=[1, 1, 1, 1], padding='SAME')\n",
    "            fineLast.append(conv + biases)\n",
    "\n",
    "    out = tf.concat(3,fineLast)\n",
    "    return out\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
