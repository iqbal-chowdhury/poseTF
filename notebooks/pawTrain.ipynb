{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Mayank Jan 12 2016\n",
    "Paw detector modified from:\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os,sys\n",
    "sys.path.append('/home/mayank/work/caffe/python')\n",
    "\n",
    "import caffe\n",
    "import lmdb\n",
    "import caffe.proto.caffe_pb2\n",
    "import pawconfig as conf\n",
    "\n",
    "from caffe.io import datum_to_array\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import multiPawTools\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import matplotlib.animation as manimation\n",
    "sys.path.append('/home/mayank/work/pyutils')\n",
    "import myutils\n",
    "import tempfile\n",
    "import copy\n",
    "from convNetBase import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paw_net_multi(X0,X1,X2, _base_weights,_weights, _biases, _dropout):\n",
    "    \n",
    "    conv5_0 = paw_net_multi_base(X0,_base_weights['base0'],_dropout)\n",
    "    conv5_1 = paw_net_multi_base(X1,_base_weights['base1'],_dropout)\n",
    "    conv5_2 = paw_net_multi_base(X2,_base_weights['base2'],_dropout)\n",
    "\n",
    "    conv5_cat = tf.concat(3,[conv5_0,conv5_1,conv5_2])\n",
    "    \n",
    "    # Reshape conv5 output to fit dense layer input\n",
    "    fc6 = tf.reshape(conv5_cat, [-1, _weights['wd1'].get_shape().as_list()[0]]) \n",
    "    fc6 = tf.nn.relu(tf.matmul(fc6, _weights['wd1']) + _biases['bd1'], name='fc6') \n",
    "    fc6 = tf.nn.dropout(fc6, _dropout)\n",
    "\n",
    "    \n",
    "    fc7 = tf.nn.relu(tf.matmul(fc6, _weights['wd2']) + _biases['bd2'], name='fc6') \n",
    "    fc7 = tf.nn.dropout(fc7, _dropout)\n",
    "    \n",
    "    # Output, class prediction\n",
    "    out = tf.matmul(fc7, _weights['out']) + _biases['out']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paw_net_multi_conv(X0,X1,X2, _weights,_dropout):\n",
    "    imsz = conf.imsz\n",
    "    pool_scale = conf.pool_scale\n",
    "    rescale = conf.rescale\n",
    "    conv5_0 = paw_net_multi_base(X0,_weights['base0'])\n",
    "    conv5_1 = paw_net_multi_base(X1,_weights['base1'])\n",
    "    conv5_2 = paw_net_multi_base(X2,_weights['base2'])\n",
    "\n",
    "    sz0 = int(math.ceil(float(imsz[0])/pool_scale/rescale))\n",
    "    sz1 = int(math.ceil(float(imsz[1])/pool_scale/rescale))\n",
    "    conv5_1_up = upscale('5_1',conv5_1,[sz0,sz1])\n",
    "    conv5_2_up = upscale('5_2',conv5_2,[sz0,sz1])\n",
    "    conv5_cat = tf.concat(3,[conv5_0,conv5_1_up,conv5_2_up])\n",
    "    \n",
    "    # Reshape conv5 output to fit dense layer input\n",
    "    conv6 = conv2d('conv6',conv5_cat,_weights['wd1'],_weights['bd1']) \n",
    "    conv6 = tf.nn.dropout(conv6,_dropout)\n",
    "    conv7 = conv2d('conv7',conv6,_weights['wd2'],_weights['bd2']) \n",
    "    conv7 = tf.nn.dropout(conv7,_dropout)\n",
    "    # Output, class prediction\n",
    "    out = tf.nn.bias_add(tf.nn.conv2d(\n",
    "            conv7, _weights['wd3'], \n",
    "            strides=[1, 1, 1, 1], padding='SAME'),_weights['bd3'])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createPlaceHolders():\n",
    "    imsz = conf.imsz\n",
    "    # tf Graph input\n",
    "    keep_prob = tf.placeholder(tf.float32) # dropout(keep probability)\n",
    "    x0 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/conf.rescale,\n",
    "                                     imsz[1]/conf.rescale,1])\n",
    "    x1 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/conf.scale/conf.rescale,\n",
    "                                     imsz[1]/conf.scale/conf.rescale,1])\n",
    "    x2 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/conf.scale/conf.scale/conf.rescale,\n",
    "                                     imsz[1]/conf.scale/conf.scale/conf.rescale,1])\n",
    "\n",
    "    lsz0 = int(math.ceil(float(imsz[0])/conf.pool_scale/conf.rescale))\n",
    "    lsz1 = int(math.ceil(float(imsz[1])/conf.pool_scale/conf.rescale))\n",
    "    y = tf.placeholder(tf.float32, [None, lsz0,lsz1,conf.n_classes])\n",
    "    return x0,x1,x2,y,keep_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiScaleImages(inImg):\n",
    "    x0_in = multiPawTools.scaleImages(inImg,conf.rescale)\n",
    "    x1_in = multiPawTools.scaleImages(x0_in,conf.scale)\n",
    "    x2_in = multiPawTools.scaleImages(x1_in,conf.scale)\n",
    "    return x0_in,x1_in,x2_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Parameters\n",
    "    learning_rate = conf.learning_rate\n",
    "    training_iters = conf.training_iters\n",
    "    batch_size = conf.batch_size\n",
    "    display_step = conf.display_step\n",
    "\n",
    "    # Network Parameters\n",
    "    n_input = conf.psz\n",
    "    n_classes = conf.n_classes # \n",
    "    dropout = conf.dropout # Dropout, probability to keep units\n",
    "    x0,x1,x2,y,keep_prob = createPlaceHolders()\n",
    "    \n",
    "    lmdbfilename =os.path.join(conf.cachedir,conf.trainfilename)\n",
    "    vallmdbfilename =os.path.join(conf.cachedir,conf.valfilename)\n",
    "    env = lmdb.open(lmdbfilename, map_size=conf.map_size)\n",
    "    valenv = lmdb.open(vallmdbfilename, map_size=conf.map_size)\n",
    "    weights = initNetConvWeights()\n",
    "    \n",
    "    with env.begin(write=True) as txn,valenv.begin(write=True) as valtxn:\n",
    "        train_cursor = txn.cursor()\n",
    "        val_cursor = valtxn.cursor()\n",
    "\n",
    "        # Construct model\n",
    "        pred = paw_net_multi_conv(x0,x1,x2, weights, keep_prob)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        cost = tf.reduce_mean(tf.nn.l2_loss(pred- y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            print(\"Initialized the network\")\n",
    "            step = 1\n",
    "            # Keep training until reach max iterations\n",
    "            while step < training_iters:\n",
    "                batch_xs, locs = multiPawTools.readLMDB(train_cursor,batch_size,n_classes)\n",
    "\n",
    "                x0_in,x1_in,x2_in = multiScaleImages(batch_xs.transpose([0,2,3,1]))\n",
    "                labelims = multiPawTools.createLabelImages(locs,\n",
    "                                           conf.imsz,conf.pool_scale*conf.rescale,\n",
    "                                           conf.label_blur_rad,1) \n",
    "                sess.run(optimizer, \n",
    "                         feed_dict={x0: x0_in,\n",
    "                                    x1: x1_in,\n",
    "                                    x2: x2_in,\n",
    "                                    y: labelims, keep_prob: dropout})\n",
    "\n",
    "                if step % display_step == 0:\n",
    "                    train_loss = sess.run(cost, feed_dict={x0:x0_in,\n",
    "                                                     x1:x1_in,\n",
    "                                                     x2:x2_in,\n",
    "                                               y: labelims, keep_prob: 1.})\n",
    "                    \n",
    "                    numrep = int(conf.numTest/conf.batch_size)+1\n",
    "                    acc = 0; loss = 0\n",
    "                    for rep in range(numrep):\n",
    "                        val_xs, locs = multiPawTools.readLMDB(val_cursor,batch_size,n_classes)\n",
    "                        x0_in,x1_in,x2_in = multiScaleImages(val_xs.transpose([0,2,3,1]))\n",
    "\n",
    "                        labelims = multiPawTools.createLabelImages(locs,\n",
    "                                                   conf.imsz,conf.pool_scale*conf.rescale,\n",
    "                                                   conf.label_blur_rad,1)\n",
    "                        loss += sess.run(cost, feed_dict={x0:x0_in,\n",
    "                                                         x1:x1_in,\n",
    "                                                         x2:x2_in,\n",
    "                                                   y: labelims, keep_prob: 1.})\n",
    "                    loss = loss/numrep\n",
    "                    print \" Iter \" + str(step) + \", Training Loss= \" + \"{:.6f}\".format(train_loss)\n",
    "                    print \" Iter \" + str(step) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) \n",
    "                if step % conf.save_step == 0:\n",
    "                    curoutname = '%s_%d.ckpt'% (conf.outname,step)\n",
    "                    outfilename = os.path.join(conf.cachedir,curoutname)\n",
    "                    saver.save(sess,outfilename)\n",
    "                    print('Saved state to %s' %(outfilename))\n",
    "\n",
    "                step += 1\n",
    "            print \"Optimization Finished!\"\n",
    "            curoutname = '%s_%d.ckpt'% (conf.outname,step)\n",
    "            outfilename = os.path.join(conf.cachedir,curoutname)\n",
    "            saver.save(sess,outfilename)\n",
    "            print('Saved state to %s' %(outfilename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initPredSession():\n",
    "    x0,x1,x2,y,keep_prob = createPlaceHolders()\n",
    "    weights = initNetConvWeights()\n",
    "    pred = paw_net_multi_conv(x0,x1,x2, weights, keep_prob)\n",
    "    saver = tf.train.Saver()\n",
    "    pholders = (x0,x1,x2,y,keep_prob)\n",
    "    return pred, saver,pholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(img,sess,pred,pholders):\n",
    "    x0_in,x1_in,x2_in = multiScaleImages(img[np.newaxis,:,:,:])\n",
    "    imsz = conf.imsz\n",
    "    lsz0 = int(math.ceil(float(imsz[0])/conf.pool_scale/conf.rescale))\n",
    "    lsz1 = int(math.ceil(float(imsz[1])/conf.pool_scale/conf.rescale))\n",
    "\n",
    "    labelim = np.zeros([1,lsz0,lsz1,1])\n",
    "\n",
    "    out = sess.run(pred,feed_dict={pholders[0]:x0_in,\n",
    "                     pholders[1]:x1_in,\n",
    "                     pholders[2]:x2_in,\n",
    "                     pholders[3]:labelim,\n",
    "                     pholders[4]: 1.})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictMovie(model_file,inmovie,outmovie):\n",
    "    pred,saver,pholders = initPredSession()\n",
    "    tdir = tempfile.mkdtemp()\n",
    "\n",
    "    cap = cv2.VideoCapture(inmovie)\n",
    "    nframes = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))\n",
    "    plt.gray()\n",
    "    # with writer.saving(fig,\"test_results.mp4\",4):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, model_file)\n",
    "        \n",
    "        count = 0\n",
    "        for fnum in range(nframes):\n",
    "            plt.clf()\n",
    "            plt.axis('off')\n",
    "            framein = myutils.readframe(cap,fnum)\n",
    "            framein = framein[:,0:(framein.shape[1]/2),0:1]\n",
    "            out = predict(copy.copy(framein),sess,pred,pholders)\n",
    "            plt.imshow(framein[:,:,0])\n",
    "            maxndx = np.argmax(out[0,:,:,0])\n",
    "            loc = np.unravel_index(maxndx,out.shape[1:3])\n",
    "            scalefactor = conf.rescale*conf.pool_scale\n",
    "            plt.scatter(loc[1]*scalefactor,loc[0]*scalefactor,hold=True)\n",
    "\n",
    "            fname = \"test_{:06d}.png\".format(count)\n",
    "            plt.savefig(os.path.join(tdir,fname))\n",
    "            count+=1\n",
    "\n",
    "#     ffmpeg_cmd = \"ffmpeg -r 30 \" + \\\n",
    "#     \"-f image2 -i '/path/to/your/picName%d.png' -qscale 0 '/path/to/your/new/video.avi'\n",
    "\n",
    "    tfilestr = os.path.join(tdir,'test_*.png')\n",
    "    mencoder_cmd = \"mencoder mf://\" + tfilestr + \\\n",
    "    \" -frames \" + \"{:d}\".format(count) + \" -mf type=png:fps=15 -o \" + \\\n",
    "    outmovie + \" -ovc lavc -lavcopts vcodec=mpeg4:vbitrate=2000000\"\n",
    "#     print(mencoder_cmd)\n",
    "    os.system(mencoder_cmd)\n",
    "    cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
