{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Mayank Feb 3 2016\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import os,sys,shutil\n",
    "import tempfile,copy,re\n",
    "from enum import Enum\n",
    "import localSetup\n",
    "\n",
    "import caffe,lmdb\n",
    "import caffe.proto.caffe_pb2\n",
    "from caffe.io import datum_to_array\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as manimation\n",
    "import math,cv2,scipy,time,pickle\n",
    "import numpy as np\n",
    "\n",
    "import PoseTools,myutils,multiResData\n",
    "\n",
    "import convNetBase as CNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoseTrain:\n",
    "    \n",
    "    Nets = Enum('Nets','Base Joint Fine')\n",
    "    TrainingType = Enum('TrainingType','Base MRF Fine All')\n",
    "    DBType = Enum('DBType','Train Val')\n",
    "    \n",
    "    def __init__(self,conf):\n",
    "        self.conf = conf\n",
    "        self.feed_dict = {}\n",
    "    \n",
    "    def openDBs(self):\n",
    "        lmdbfilename =os.path.join(self.conf.cachedir,self.conf.trainfilename)\n",
    "        vallmdbfilename =os.path.join(self.conf.cachedir,self.conf.valfilename)\n",
    "        self.env = lmdb.open(lmdbfilename, readonly = True)\n",
    "        self.valenv = lmdb.open(vallmdbfilename, readonly = True)\n",
    "\n",
    "    def createCursors(self,txn,valtxn):\n",
    "        self.train_cursor = txn.cursor(); \n",
    "        self.val_cursor = valtxn.cursor()\n",
    "        \n",
    "    def createPH(self):\n",
    "        x0,x1,x2,y,keep_prob = CNB.createPlaceHolders(self.conf.imsz,\n",
    "                               self.conf.rescale,self.conf.scale,self.conf.pool_scale,\n",
    "                                self.conf.n_classes)\n",
    "        locs_ph = tf.placeholder(tf.float32,[self.conf.batch_size,\n",
    "                                             self.conf.n_classes,2])\n",
    "        learning_rate_ph = tf.placeholder(tf.float32,shape=[])\n",
    "        self.ph = {'x0':x0,'x1':x1,'x2':x2,\n",
    "                     'y':y,'keep_prob':keep_prob,'locs':locs_ph,\n",
    "                     'learning_rate':learning_rate_ph}\n",
    "        \n",
    "        \n",
    "    def readImages(self,dbType):\n",
    "        conf = self.conf\n",
    "        curcursor = self.val_cursor if (dbType == self.DBType.Val) \\\n",
    "                    else self.train_cursor\n",
    "        xs, locs = PoseTools.readLMDB(curcursor,\n",
    "                         conf.batch_size,conf.imsz,multiResData)\n",
    "        locs = multiResData.sanitizelocs(locs)\n",
    "        self.xs = xs\n",
    "        self.locs = locs\n",
    "        \n",
    "\n",
    "    def createFeedDict(self):\n",
    "        self.feed_dict = {self.ph['x0']:[],\n",
    "                          self.ph['x1']:[],\n",
    "                          self.ph['x2']:[],\n",
    "                          self.ph['y']:[],\n",
    "                          self.ph['keep_prob']:1.,\n",
    "                          self.ph['learning_rate']:1,\n",
    "                          self.ph['locs']:[]}\n",
    "\n",
    "    def updateFeedDict(self,dbType):\n",
    "        conf = self.conf\n",
    "        self.readImages(dbType)\n",
    "        x0,x1,x2 = PoseTools.multiScaleImages(\n",
    "            self.xs.transpose([0,2,3,1]),conf.rescale,conf.scale)\n",
    "\n",
    "        labelims = PoseTools.createLabelImages(self.locs,\n",
    "                                   self.conf.imsz,\n",
    "                                   self.conf.pool_scale*self.conf.rescale,\n",
    "                                   self.conf.label_blur_rad)\n",
    "        self.feed_dict[self.ph['x0']] = x0\n",
    "        self.feed_dict[self.ph['x1']] = x1\n",
    "        self.feed_dict[self.ph['x2']] = x2\n",
    "        self.feed_dict[self.ph['y']] = labelims\n",
    "        self.feed_dict[self.ph['locs']] = self.locs\n",
    "        \n",
    "    \n",
    "    def createBaseNetwork(self):\n",
    "        pred,layers = CNB.net_multi_conv(self.ph['x0'],\n",
    "                                     self.ph['x1'],\n",
    "                                     self.ph['x2'],\n",
    "                                     self.ph['keep_prob'],self.conf)\n",
    "        self.basePred = pred\n",
    "        self.baseLayers = layers\n",
    "\n",
    "    def createMRFNetwork(self,passGradients=False):\n",
    "        \n",
    "        ncls = self.conf.n_classes\n",
    "        bpred = self.basePred if passGradients else tf.stop_gradient(self.basePred)\n",
    "        mrf_weights = PoseTools.initMRFweights(self.conf).astype('float32')\n",
    "        ksz = mrf_weights[0] # Kernel is square for time being\n",
    "        mrf_conv = 0\n",
    "        for cls in range(ncls):\n",
    "            with tf.variable_scope('mrf_%d'%cls):\n",
    "                weights = tf.get_variable(\"weights\",dtype = tf.float32,\n",
    "                              initializer=tf.constant(mrf_weights[:,:,cls:cls+1,:]-1.2))\n",
    "                biases = tf.get_variable(\"biases\", mrf_weights.shape[-1],dtype = tf.float32,\n",
    "                              initializer=tf.constant_initializer(-1))\n",
    "\n",
    "            sweights = tf.nn.softplus(weights)\n",
    "            sbiases = tf.nn.softplus(biases)\n",
    "            curconv = tf.nn.conv2d(tf.maximum(bpred[:,:,:,cls:cls+1],0.0001), \n",
    "                           sweights,strides=[1, 1, 1, 1], padding='SAME')+sbiases\n",
    "            mrf_conv += tf.log(curconv)\n",
    "        self.mrfPred = tf.exp(mrf_conv)\n",
    "\n",
    "        \n",
    "    def createFineNetwork(self):\n",
    "        if self.curtrainingType == self.TrainingType.All:\n",
    "            pred = tf.stop_gradient(self.basePred)\n",
    "        else:\n",
    "            pred = self.basePred\n",
    "\n",
    "        # Construct fine model\n",
    "        labelT  = PoseTools.createFineLabelTensor(self.conf)\n",
    "        layers = self.baseLayers\n",
    "        layer1_1 = tf.stop_gradient(layers['base_dict_0']['conv1'])\n",
    "        layer1_2 = tf.stop_gradient(layers['base_dict_0']['conv2'])\n",
    "        layer2_1 = tf.stop_gradient(layers['base_dict_1']['conv1'])\n",
    "        layer2_2 = tf.stop_gradient(layers['base_dict_1']['conv2'])\n",
    "        curfine1_1 = CNB.extractPatches(layer1_1,pred,self.conf,1,4)\n",
    "        curfine1_2 = CNB.extractPatches(layer1_2,pred,self.conf,2,2)\n",
    "        curfine2_1 = CNB.extractPatches(layer2_1,pred,self.conf,2,2)\n",
    "        curfine2_2 = CNB.extractPatches(layer2_2,pred,self.conf,4,1)\n",
    "        curfine1_1u = tf.unpack(tf.transpose(curfine1_1,[1,0,2,3,4]))\n",
    "        curfine1_2u = tf.unpack(tf.transpose(curfine1_2,[1,0,2,3,4]))\n",
    "        curfine2_1u = tf.unpack(tf.transpose(curfine2_1,[1,0,2,3,4]))\n",
    "        curfine2_2u = tf.unpack(tf.transpose(curfine2_2,[1,0,2,3,4]))\n",
    "        finepred = CNB.fineOut(curfine1_1u,curfine1_2u,curfine2_1u,curfine2_2u,self.conf)    \n",
    "        limgs = PoseTools.createFineLabelImages(self.conf.ph['locs'],\n",
    "                                                    pred,self.conf,labelT)\n",
    "        \n",
    "        self.finePred = finepred\n",
    "        self.fine_labels = limgs\n",
    "\n",
    "    def createBaseSaver(self):\n",
    "        self.basesaver = tf.train.Saver(var_list = PoseTools.getvars('base'),\n",
    "                                        max_to_keep=self.conf.maxckpt)\n",
    "        \n",
    "    def createMRFSaver(self):\n",
    "        var_list = PoseTools.getvars('mrf')\n",
    "        self.mrfsaver = tf.train.Saver(var_list = PoseTools.getvars('mrf'),\n",
    "                                       max_to_keep=self.conf.maxckpt)\n",
    "        \n",
    "    def createFineSaver(self):\n",
    "        self.finesaver = tf.train.Saver(var_list = PoseTools.getvars('fine'),\n",
    "                                        max_to_keep=self.conf.maxckpt)\n",
    "        \n",
    "    def loadBase(self):\n",
    "        baseoutname = '%s_%d.ckpt'%(self.conf.outname,self.conf.base_training_iters)\n",
    "        basemodelfile = os.path.join(self.conf.cachedir,baseoutname)\n",
    "\n",
    "        self.basesaver.restore(self.sess,basemodelfile)\n",
    "\n",
    "    def saveBase(self,sess,step):\n",
    "        \n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.outname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.databasename)\n",
    "        self.basesaver.save(sess,outfilename,global_step=step,\n",
    "                   latest_filename = self.conf.ckptbasename)\n",
    "        print('Saved state to %s-%d' %(outfilename,step))\n",
    "#         if step%self.conf.back_steps==0:\n",
    "#             shutil.copyfile('%s-%d'%(outfilename,step),'%s-%d.save'%(outfilename,step))\n",
    "#             print('Backed up state to %s-%d.save' %(outfilename,step))\n",
    "            \n",
    "        with open(traindatafilename,'wb') as tdfile:\n",
    "            pickle.dump(self.basetrainData,tdfile)\n",
    "\n",
    "    def restoreBase(self,sess,restore):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.outname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.databasename)\n",
    "        latest_ckpt = tf.train.get_checkpoint_state(self.conf.cachedir,\n",
    "                                            latest_filename = self.conf.ckptbasename)\n",
    "        if not latest_ckpt or not restore:\n",
    "            self.basestartat = 0\n",
    "            self.basetrainData = {'train_err':[],'val_err':[],'step_no':[]}\n",
    "            sess.run(tf.initialize_variables(PoseTools.getvars('base')))\n",
    "            print(\"Not loading base variables. Initializing them\")\n",
    "            return False\n",
    "        else:\n",
    "            self.basesaver.restore(sess,latest_ckpt.model_checkpoint_path)\n",
    "            matchObj = re.match(outfilename + '-(\\d*)',latest_ckpt.model_checkpoint_path)\n",
    "            self.basestartat = int(matchObj.group(1))+1\n",
    "            with open(traindatafilename,'rb') as tdfile:\n",
    "                self.basetrainData = pickle.load(tdfile)\n",
    "            print(\"Loading base variables from %s\"%latest_ckpt.model_checkpoint_path)\n",
    "            return True\n",
    "            \n",
    "    def loadBase(self,sess,iterNum):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.outname)\n",
    "        ckptfilename = '%s-%d'%(outfilename,iterNum)\n",
    "        print('Loading base from %s'%(ckptfilename))\n",
    "        self.basesaver.restore(sess,ckptfilename)\n",
    "            \n",
    "    def restoreMRF(self,sess,restore):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.mrfoutname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.datamrfname)\n",
    "        latest_ckpt = tf.train.get_checkpoint_state(self.conf.cachedir,\n",
    "                                            latest_filename = self.conf.ckptmrfname)\n",
    "        if not latest_ckpt or not restore:\n",
    "            self.mrfstartat = 0\n",
    "            self.mrftrainData = {'train_err':[],'val_err':[],'step_no':[],\n",
    "                                'train_base_err':[],'val_base_err':[]}\n",
    "            sess.run(tf.initialize_variables(PoseTools.getvars('mrf')))\n",
    "            print(\"Not loading mrf variables. Initializing them\")\n",
    "            return False\n",
    "        else:\n",
    "            self.mrfsaver.restore(sess,latest_ckpt.model_checkpoint_path)\n",
    "            matchObj = re.match(outfilename + '-(\\d*)',latest_ckpt.model_checkpoint_path)\n",
    "            self.mrfstartat = int(matchObj.group(1))+1\n",
    "            with open(traindatafilename,'rb') as tdfile:\n",
    "                self.mrftrainData = pickle.load(tdfile)\n",
    "            print(\"Loading mrf variables from %s\"%latest_ckpt.model_checkpoint_path)\n",
    "            return True\n",
    "            \n",
    "    def saveMRF(self,sess,step):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.mrfoutname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.datamrfname)\n",
    "        self.mrfsaver.save(sess,outfilename,global_step=step,\n",
    "                   latest_filename = self.conf.ckptmrfname)\n",
    "        print('Saved state to %s-%d' %(outfilename,step))\n",
    "        with open(traindatafilename,'wb') as tdfile:\n",
    "            pickle.dump(self.mrftrainData,tdfile)\n",
    "\n",
    "    def restoreFine(self,sess,restore):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.fineoutname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.datafinename)\n",
    "        latest_ckpt = tf.train.get_checkpoint_state(self.conf.cachedir,\n",
    "                                            latest_filename = self.conf.ckptfinename)\n",
    "        if not latest_ckpt or not restore:\n",
    "            self.finestartat = 0\n",
    "            self.finetrainData = {'train_err':[],'val_err':[],'step_no':[],\n",
    "                                'train_mrf_err':[],'val_mrf_err':[],\n",
    "                                'train_base_err':[],'val_base_err':[]}\n",
    "            sess.run(tf.initialize_variables(PoseTools.getvars('fine')))\n",
    "            print(\"Not loading fine variables. Initializing them\")\n",
    "            return False\n",
    "        else:\n",
    "            self.finesaver.restore(sess,latest_ckpt.model_checkpoint_path)\n",
    "            matchObj = re.match(outfilename + '-(\\d*)',latest_ckpt.model_checkpoint_path)\n",
    "            self.finestartat = int(matchObj.group(1))+1\n",
    "            with open(traindatafilename,'rb') as tdfile:\n",
    "                self.finetrainData = pickle.load(tdfile)\n",
    "            print(\"Loading fine variables from %s\"%latest_ckpt.model_checkpoint_path)\n",
    "            return True\n",
    "            \n",
    "    def saveFine(self,sess,step):\n",
    "        outfilename = os.path.join(self.conf.cachedir,self.conf.fineoutname)\n",
    "        traindatafilename = os.path.join(self.conf.cachedir,self.conf.datafinename)\n",
    "        self.finesaver.save(sess,outfilename,global_step=step,\n",
    "                   latest_filename = self.conf.ckptfinename)\n",
    "        print('Saved state to %s-%d' %(outfilename,step))\n",
    "        with open(traindatafilename,'wb') as tdfile:\n",
    "            pickle.dump(self.finetrainData,tdfile)\n",
    "\n",
    "\n",
    "    def createOptimizer(self):\n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate= \\\n",
    "                          self.ph['learning_rate']).minimize(self.cost)\n",
    "        self.read_time = 0.\n",
    "        self.opt_time = 0.\n",
    "\n",
    "    def doOpt(self,sess,step,learning_rate):\n",
    "        excount = step*self.conf.batch_size\n",
    "        cur_lr = learning_rate * \\\n",
    "                self.conf.gamma**math.floor(excount/self.conf.step_size)\n",
    "        self.feed_dict[self.ph['learning_rate']] = cur_lr\n",
    "        self.feed_dict[self.ph['keep_prob']] = self.conf.dropout\n",
    "        r_start = time.clock()\n",
    "        self.updateFeedDict(self.DBType.Train)\n",
    "        r_end = time.clock()\n",
    "        sess.run(self.opt, self.feed_dict)\n",
    "        o_end = time.clock()\n",
    "        \n",
    "        self.read_time += r_end-r_start\n",
    "        self.opt_time += o_end-r_end\n",
    "\n",
    "    def computeLoss(self,sess,costfcns):\n",
    "        self.feed_dict[self.ph['keep_prob']] = 1.\n",
    "        loss = sess.run(costfcns,self.feed_dict)\n",
    "        loss = [x/self.conf.batch_size for x in loss]\n",
    "        return loss\n",
    "        \n",
    "    def updateBaseLoss(self,step,train_loss,val_loss):\n",
    "        print \"Iter \" + str(step) + \\\n",
    "             \", Train = \" + \"{:.3f}\".format(train_loss[0]) + \\\n",
    "             \", Val = \" + \"{:.3f}\".format(val_loss[0])\n",
    "#         nstep = step-self.basestartat\n",
    "#         print \"  Read Time:\" + \"{:.2f}, \".format(self.read_time/(nstep+1)) + \\\n",
    "#               \"Opt Time:\" + \"{:.2f}\".format(self.opt_time/(nstep+1)) \n",
    "        self.basetrainData['train_err'].append(train_loss[0])      \n",
    "        self.basetrainData['val_err'].append(val_loss[0])        \n",
    "        self.basetrainData['step_no'].append(step)        \n",
    "\n",
    "    def updateMRFLoss(self,step,train_loss,val_loss):\n",
    "        print \"Iter \" + str(step) + \\\n",
    "             \", Train = \" + \"{:.3f}\".format(train_loss[0]) + \\\n",
    "             \", Val = \" + \"{:.3f}\".format(val_loss[0]) + \\\n",
    "             \" ({:.1f},{:.1f})\".format(train_loss[1],val_loss[1])\n",
    "#         nstep = step-self.basestartat\n",
    "#         print \"  Read Time:\" + \"{:.2f}, \".format(self.read_time/(nstep+1)) + \\\n",
    "#               \"Opt Time:\" + \"{:.2f}\".format(self.opt_time/(nstep+1)) \n",
    "        self.mrftrainData['train_err'].append(train_loss)        \n",
    "        self.mrftrainData['val_err'].append(val_loss[0])        \n",
    "        self.mrftrainData['train_base_err'].append(train_loss[1])        \n",
    "        self.mrftrainData['val_base_err'].append(val_loss[1])        \n",
    "        self.mrftrainData['step_no'].append(step)        \n",
    "\n",
    "    def updateFineLoss(self,step,train_loss,val_loss):\n",
    "        print \"Iter \" + str(step) + \\\n",
    "             \", Train = \" + \"{:.3f}\".format(train_loss[0]) + \\\n",
    "             \", Val = \" + \"{:.3f}\".format(val_loss[0]) + \\\n",
    "             \" ({:.1f},{:.1f})\".format(train_loss[1],val_loss[1]) + \\\n",
    "             \" ({:.1f},{:.1f})\".format(train_loss[2],val_loss[2])\n",
    "#         nstep = step-self.basestartat\n",
    "#         print \"  Read Time:\" + \"{:.2f}, \".format(self.read_time/(nstep+1)) + \\\n",
    "#               \"Opt Time:\" + \"{:.2f}\".format(self.opt_time/(nstep+1)) \n",
    "        self.mrftrainData['train_err'].append(train_loss)        \n",
    "        self.mrftrainData['val_err'].append(val_loss[0])        \n",
    "        self.mrftrainData['train_mrf_err'].append(train_loss[1])        \n",
    "        self.mrftrainData['val_mrf_err'].append(val_loss[1])        \n",
    "        self.mrftrainData['train_base_err'].append(train_loss[2])        \n",
    "        self.mrftrainData['val_base_err'].append(val_loss[2])        \n",
    "        self.mrftrainData['step_no'].append(step)        \n",
    "\n",
    "    def initializeRemainingVars(self,sess):\n",
    "        varlist = tf.all_variables()\n",
    "        for var in varlist:\n",
    "            try:\n",
    "                sess.run(tf.assert_variables_initialized([var]))\n",
    "            except tf.errors.FailedPreconditionError:\n",
    "                sess.run(tf.initialize_variables([var]))\n",
    "                print('Initializing variable:%s'%var.name)\n",
    "\n",
    "    def baseTrain(self,restore=True):\n",
    "        self.createPH()\n",
    "        self.createFeedDict()\n",
    "        with tf.variable_scope('base'):\n",
    "            self.createBaseNetwork()\n",
    "        self.cost = tf.nn.l2_loss(self.basePred-self.ph['y'])\n",
    "        self.openDBs()\n",
    "        self.createOptimizer()\n",
    "        self.createBaseSaver()\n",
    "        with self.env.begin() as txn,self.valenv.begin() as valtxn, tf.Session() as sess:\n",
    "            self.createCursors(txn,valtxn)\n",
    "            self.restoreBase(sess,restore)\n",
    "            self.initializeRemainingVars(sess)\n",
    "\n",
    "            for step in range(self.basestartat,self.conf.base_training_iters):\n",
    "                self.doOpt(sess,step,self.conf.base_learning_rate)\n",
    "                if step % self.conf.display_step == 0:\n",
    "                    self.updateFeedDict(self.DBType.Train)\n",
    "                    train_loss = self.computeLoss(sess,[self.cost])\n",
    "                    numrep = int(self.conf.numTest/self.conf.batch_size)+1\n",
    "                    val_loss = np.zeros([2,])\n",
    "                    for rep in range(numrep):\n",
    "                        self.updateFeedDict(self.DBType.Val)\n",
    "                        val_loss += np.array(self.computeLoss(sess,[self.cost]))\n",
    "                    val_loss = val_loss/numrep\n",
    "                    self.updateBaseLoss(step,train_loss,val_loss)\n",
    "                if step % self.conf.save_step == 0:\n",
    "                    self.saveBase(sess,step)\n",
    "            print(\"Optimization Finished!\")\n",
    "            self.saveBase(sess,step)\n",
    "    \n",
    "        \n",
    "    def mrfTrain(self,restore=True):\n",
    "        self.createPH()\n",
    "        self.createFeedDict()\n",
    "        with tf.variable_scope('base'):\n",
    "            self.createBaseNetwork()\n",
    "\n",
    "        with tf.variable_scope('mrf'):\n",
    "            self.createMRFNetwork()\n",
    "\n",
    "        self.createBaseSaver()\n",
    "        self.createMRFSaver()\n",
    "\n",
    "        mod_labels = (self.ph['y']+1.)/2\n",
    "        self.cost = tf.nn.l2_loss(self.mrfPred-mod_labels)\n",
    "        basecost =  tf.nn.l2_loss(self.basePred-self.ph['y'])\n",
    "        self.openDBs()\n",
    "\n",
    "        self.createOptimizer()\n",
    "        \n",
    "        with self.env.begin() as txn,self.valenv.begin() as valtxn,tf.Session() as sess:\n",
    "\n",
    "            self.loadBase(sess,self.conf.baseIter4MRFTrain)\n",
    "            self.restoreMRF(sess,restore)\n",
    "            self.initializeRemainingVars(sess)\n",
    "            self.createCursors(txn,valtxn)\n",
    "            \n",
    "            for step in range(self.mrfstartat,self.conf.mrf_training_iters):\n",
    "                self.doOpt(sess,step,self.conf.mrf_learning_rate)\n",
    "                if step % self.conf.display_step == 0:\n",
    "                    self.updateFeedDict(self.DBType.Train)\n",
    "                    train_loss = self.computeLoss(sess,[self.cost,basecost])\n",
    "                    numrep = int(self.conf.numTest/self.conf.batch_size)+1\n",
    "                    val_loss = np.zeros([2,])\n",
    "                    for rep in range(numrep):\n",
    "                        self.updateFeedDict(self.DBType.Val)\n",
    "                        val_loss += np.array(self.computeLoss(sess,[self.cost,basecost]))\n",
    "                    val_loss = val_loss/numrep\n",
    "                    self.updateMRFLoss(step,train_loss,val_loss)\n",
    "                if step % self.conf.save_step == 0:\n",
    "                    self.saveMRF(sess,step)\n",
    "            print(\"Optimization Finished!\")\n",
    "            self.saveMRF(sess,step)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
