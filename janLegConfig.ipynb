{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "import os,socket\n",
    "import localSetup\n",
    "\n",
    "class myconfig(object):\n",
    "    expname = 'janLeg'\n",
    "    baseName = 'Base'\n",
    "    fineName = 'Fine'\n",
    "    mrfName = 'MRF'\n",
    "    \n",
    "    # ----- Network Parameters\n",
    "\n",
    "    scale = 2\n",
    "    rescale = 1\n",
    "    numscale = 3\n",
    "    pool_scale = 4\n",
    "    # sel_sz determines the patch size used for the final decision\n",
    "    # i.e., patch seen by the fc6 layer\n",
    "    # ideally as large as possible but limited by\n",
    "    # a) gpu memory size\n",
    "    # b) overfitting due to large number of variables.\n",
    "    sel_sz = 512/2/2\n",
    "    psz = sel_sz/(scale**(numscale-1))/rescale/pool_scale\n",
    "    label_blur_rad = 1.5\n",
    "    fine_label_blur_rad = 1.5\n",
    "    n_classes = 4 \n",
    "    dropout = 0.5\n",
    "    nfilt = 128\n",
    "    nfcfilt = 512\n",
    "    doBatchNorm = True\n",
    "    useMRF = True\n",
    "\n",
    "    # ----- Fine Network parameters\n",
    "    fine_flt_sz = 5\n",
    "    fine_nfilt = 48\n",
    "    fine_sz = 48\n",
    "\n",
    "    # ----- MRF Network Parameters\n",
    "    baseIter4MRFTrain = 5000\n",
    "\n",
    "\n",
    "    # ----- Learning parameters\n",
    "\n",
    "    base_learning_rate = 0.0003\n",
    "    mrf_learning_rate = 0.00001\n",
    "    fine_learning_rate = 0.0003\n",
    "    base_training_iters = 8000 # for a batch size of 32\n",
    "    fine_training_iters = 3000\n",
    "    mrf_training_iters = 3000\n",
    "    gamma = 0.1\n",
    "    step_size = 200000\n",
    "    batch_size = 16\n",
    "    display_step = 30\n",
    "    numTest = 100\n",
    "\n",
    "\n",
    "    # ----- Data parameters\n",
    "\n",
    "    imsz = (256,256)\n",
    "    split = True\n",
    "    view = 0\n",
    "    cropsz = 0\n",
    "    map_size = 100000*imsz[0]*imsz[1]*3\n",
    "    cropLoc = {(256,256):[0,0]}\n",
    "    cachedir = os.path.join(localSetup.bdir,'cachejanLeg/')\n",
    "    labelfile = os.path.join(localSetup.bdir,'janLegTracking','janLegData_20160301.mat')\n",
    "    # this label file has more data and includes the correction for vertical flipping\n",
    "    ptn = '.*'\n",
    "    trainfilename = 'train_lmdb'\n",
    "    valfilename = 'val_lmdb'\n",
    "    valdatafilename = 'valdata'\n",
    "    valratio = 0.3\n",
    "\n",
    "\n",
    "    # ----- Save parameters\n",
    "\n",
    "    save_step = 500\n",
    "    maxckpt = 20\n",
    "    baseoutname = expname + baseName\n",
    "    fineoutname = expname + fineName\n",
    "    mrfoutname = expname + mrfName\n",
    "    baseckptname = baseoutname + 'ckpt'\n",
    "    fineckptname = fineoutname + 'ckpt'\n",
    "    mrfckptname = mrfoutname + 'ckpt'\n",
    "    basedataname = baseoutname + 'traindata'\n",
    "    finedataname = fineoutname + 'traindata'\n",
    "    mrfdataname = mrfoutname + 'traindata'\n",
    "\n",
    "\n",
    "    def getexpname(self,dirname):\n",
    "        expname = os.path.basename(dirname)\n",
    "        return expname\n",
    "\n",
    "    def getexplist(self,L):\n",
    "        fname = 'vid{:d}files'.format(view+1)\n",
    "        return L[fname]\n",
    "\n",
    "conf = myconfig()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
